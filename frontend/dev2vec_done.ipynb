{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "fGnz3gm22efF"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Note: GitHub profiles with many repositories may result in error due to GitHub API rate limits**\n",
        "\n",
        "GitHub profiles of the following users have been compared\n",
        "\n",
        "https://github.com/ps-2810 - Back end developer\n",
        "\n",
        "https://github.com/kkistheorz - Front end developer"
      ],
      "metadata": {
        "id": "tgAylGzcyZo2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Define Parameters"
      ],
      "metadata": {
        "id": "n4FVfSBfd-2j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "task = 'Create a Task Manager Web App that allows users to efficiently manage their daily tasks'\n",
        "num_recommend = 2 #number of users to be recommended\n",
        "top_k = 1 #Average of top_k matching sentences"
      ],
      "metadata": {
        "id": "qgZqh6E4eFuA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Get the usernames from github profiles and make a dataframe (you can also use a file with a list of github usernames)"
      ],
      "metadata": {
        "id": "p-fCr-lHxTGH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "LtQMs3jo5FX_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "developers = ['https://github.com/ps-2810', 'https://github.com/kkistheorz']"
      ],
      "metadata": {
        "id": "qau2lRUX5OA6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "usernames = []\n",
        "for devs in developers:\n",
        "  usernames.append(devs.split('/')[3])"
      ],
      "metadata": {
        "id": "HtONQXG25dTs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upload file below (if you already have a list of usernames)"
      ],
      "metadata": {
        "id": "XLtVbvYFxmBq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame()\n",
        "df['dev'] = usernames"
      ],
      "metadata": {
        "id": "zTk69p8X5KTt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Get repository information from GitHub"
      ],
      "metadata": {
        "id": "ftHGVzKcx1Gd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Importing libraries"
      ],
      "metadata": {
        "id": "tcId-fTqx6BL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0H_rEjRcyWot",
        "outputId": "5c777ab3-2ccd-4aa1-9d01-0b3c7b68174c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyGithub\n",
            "  Downloading PyGithub-2.1.1-py3-none-any.whl (302 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.9/302.9 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pynacl>=1.4.0 (from PyGithub)\n",
            "  Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (856 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m856.7/856.7 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from PyGithub) (2.8.2)\n",
            "Requirement already satisfied: requests>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from PyGithub) (2.31.0)\n",
            "Collecting pyjwt[crypto]>=2.4.0 (from PyGithub)\n",
            "  Downloading PyJWT-2.8.0-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from PyGithub) (4.5.0)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from PyGithub) (2.0.7)\n",
            "Collecting Deprecated (from PyGithub)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: cryptography>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from pyjwt[crypto]>=2.4.0->PyGithub) (41.0.7)\n",
            "Requirement already satisfied: cffi>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from pynacl>=1.4.0->PyGithub) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.14.0->PyGithub) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.14.0->PyGithub) (3.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.14.0->PyGithub) (2023.11.17)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from Deprecated->PyGithub) (1.14.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil->PyGithub) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.4.1->pynacl>=1.4.0->PyGithub) (2.21)\n",
            "Installing collected packages: pyjwt, Deprecated, pynacl, PyGithub\n",
            "  Attempting uninstall: pyjwt\n",
            "    Found existing installation: PyJWT 2.3.0\n",
            "    Uninstalling PyJWT-2.3.0:\n",
            "      Successfully uninstalled PyJWT-2.3.0\n",
            "Successfully installed Deprecated-1.2.14 PyGithub-2.1.1 pyjwt-2.8.0 pynacl-1.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install PyGithub"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim==3.7.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "myPqFvV6Cx1Y",
        "outputId": "6493585c-b886-49f3-d106-ae8cd090224d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gensim==3.7.0\n",
            "  Downloading gensim-3.7.0.tar.gz (23.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.4/23.4 MB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.10/dist-packages (from gensim==3.7.0) (1.23.5)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.10/dist-packages (from gensim==3.7.0) (1.11.4)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from gensim==3.7.0) (1.16.0)\n",
            "Requirement already satisfied: smart_open>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim==3.7.0) (6.4.0)\n",
            "Building wheels for collected packages: gensim\n",
            "  Building wheel for gensim (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gensim: filename=gensim-3.7.0-cp310-cp310-linux_x86_64.whl size=24585051 sha256=d7918355bc020d95fbd52521a22ec69c1b21543183a043b3c901c0a108d4c44b\n",
            "  Stored in directory: /root/.cache/pip/wheels/dc/47/f9/022929f4b4de4a3be6f7f59ecef50db175700f594787f7caed\n",
            "Successfully built gensim\n",
            "Installing collected packages: gensim\n",
            "  Attempting uninstall: gensim\n",
            "    Found existing installation: gensim 4.3.2\n",
            "    Uninstalling gensim-4.3.2:\n",
            "      Successfully uninstalled gensim-4.3.2\n",
            "Successfully installed gensim-3.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is a problem with gensim package.\n",
        "Two ways to fix it:\n",
        "https://drive.google.com/drive/folders/1h3hg8jdVhL3pPkF3Zww700vXqzpKcQ-g?usp=sharing\n",
        "1. Use the gensim package used in the above zip file\n",
        "\n",
        "OR\n",
        "2. In the dictionary.py file in the gensim 3.7.0 package:\n",
        "replace\n",
        "**from collections import Mapping, defaultdict**\n",
        "\n",
        "to\n",
        "\n",
        "**from collections.abc import Mapping**\n",
        "\n",
        "**from collections import defaultdict**"
      ],
      "metadata": {
        "id": "_OYPtXztzYb0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "from gensim.models.doc2vec import Doc2Vec"
      ],
      "metadata": {
        "id": "UkboMI2eC1KS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"gensim\", gensim.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ZvXUAttC5v9",
        "outputId": "ae1ab37e-8425-4694-9f48-294ea8dc3e44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gensim 3.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "from github import Github\n",
        "from github import RateLimitExceededException\n",
        "from github import UnknownObjectException\n",
        "from datetime import datetime, timedelta\n",
        "import pickle\n",
        "import time\n",
        "import itertools\n",
        "import os\n",
        "import calendar\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import string\n",
        "import requests\n",
        "import base64"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yipsOBUJzMfK",
        "outputId": "d5bb7f61-97ad-4956-c613-959d26792f1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Downloading the pretrained dev2vec model"
      ],
      "metadata": {
        "id": "3s0-CWZ1x_Pk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1pfU1uwe5qXw1H6nFYzeobFwBZUBfy_f0\n",
        "!gdown 1Ie-9pc5qCyC8FHqe6S620C5s_gaWmyvT\n",
        "!gdown 13OW3YenkWXRDjEhyUnq0FRhWASlaCbAP\n",
        "!gdown 1nBJZzuIgy7ujeEoHnvDvbVadLCcEOxn_\n",
        "!gdown 1RCVSnc9SkQP0Qh5mvjKKNJdWghddgGPT\n",
        "!gdown 1R5B1urqgYPhu-89FP5e0I0VEqH9L9REr\n",
        "!gdown 19nmPPoIUxxycGqXETPt4jga9yS_4ozVS\n",
        "!gdown 16x9JlHxY8yH1cM8f5M5gwKwZzH5OOCKN"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLtI0e9jCphs",
        "outputId": "1db05d23-825d-458a-ea9e-640afaa8ae99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1pfU1uwe5qXw1H6nFYzeobFwBZUBfy_f0\n",
            "To: /content/dev2vec_issues.wv.vectors.npy\n",
            "100% 4.26M/4.26M [00:00<00:00, 67.8MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Ie-9pc5qCyC8FHqe6S620C5s_gaWmyvT\n",
            "To: /content/dev2vec_issues\n",
            "100% 563k/563k [00:00<00:00, 69.4MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=13OW3YenkWXRDjEhyUnq0FRhWASlaCbAP\n",
            "To: /content/dev2vec_repos.trainables.syn1neg.npy\n",
            "100% 19.7M/19.7M [00:00<00:00, 186MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1nBJZzuIgy7ujeEoHnvDvbVadLCcEOxn_\n",
            "To: /content/dev2vec_repos\n",
            "100% 1.58M/1.58M [00:00<00:00, 170MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1RCVSnc9SkQP0Qh5mvjKKNJdWghddgGPT\n",
            "To: /content/dev2vec_issues.trainables.syn1neg.npy\n",
            "100% 4.26M/4.26M [00:00<00:00, 250MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1R5B1urqgYPhu-89FP5e0I0VEqH9L9REr\n",
            "To: /content/dev2vec_repos.docvecs.vectors_docs.npy\n",
            "100% 1.19M/1.19M [00:00<00:00, 140MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=19nmPPoIUxxycGqXETPt4jga9yS_4ozVS\n",
            "To: /content/dev2vec_repos.wv.vectors.npy\n",
            "100% 19.7M/19.7M [00:00<00:00, 75.5MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=16x9JlHxY8yH1cM8f5M5gwKwZzH5OOCKN\n",
            "To: /content/dev2vec_issues.docvecs.vectors_docs.npy\n",
            "100% 706k/706k [00:00<00:00, 111MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Get the repository information"
      ],
      "metadata": {
        "id": "_5rddnCZfg3u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_github_repositories(username):\n",
        "    url = f'https://api.github.com/users/{username}/repos'\n",
        "    response = requests.get(url)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        repositories = response.json()\n",
        "        return repositories\n",
        "    else:\n",
        "        print(f\"Error: Unable to fetch repositories. Status code: {response.status_code}\")\n",
        "        return None\n",
        "\n",
        "def get_repository_info(username, repo_name):\n",
        "    url = f'https://api.github.com/repos/{username}/{repo_name}'\n",
        "    response = requests.get(url)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        repository_info = response.json()\n",
        "        return repository_info\n",
        "    else:\n",
        "        print(f\"Error: Unable to fetch repository information. Status code: {response.status_code}\")\n",
        "        return None\n",
        "\n",
        "def get_readme_content(username, repo_name):\n",
        "    url = f'https://api.github.com/repos/{username}/{repo_name}/readme'\n",
        "    response = requests.get(url)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        readme_info = response.json()\n",
        "        readme_content_base64 = readme_info.get('content', '')\n",
        "        readme_content = base64.b64decode(readme_content_base64).decode('utf-8')\n",
        "        return readme_content\n",
        "    else:\n",
        "        print(f\"Error: Unable to fetch README content. Status code: {response.status_code}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "nAwn3sCfzOvl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def repos(github_username):\n",
        "\n",
        "  repositories = get_github_repositories(github_username)\n",
        "\n",
        "  if repositories:\n",
        "      repo_info_array = []\n",
        "\n",
        "      for repo in repositories:\n",
        "          repo_name = repo['name']\n",
        "          repo_info = get_repository_info(github_username, repo_name)\n",
        "\n",
        "          if repo_info:\n",
        "              description = repo_info.get('description', 'N/A')\n",
        "\n",
        "              readme_content = get_readme_content(github_username, repo_name)\n",
        "              if readme_content:\n",
        "                  full_info = f\"{description}. {readme_content}\"\n",
        "              else:\n",
        "                  full_info = f\"{description}. Unable to fetch README content.\"\n",
        "\n",
        "              repo_info_array.append(full_info)\n",
        "          else:\n",
        "              print(f\"Unable to fetch information for repository: {repo_name}\")\n",
        "\n",
        "      # Print or use repo_info_array as needed\n",
        "      print(\"Repository Information Array:\")\n",
        "      print(repo_info_array)\n",
        "      return repo_info_array\n",
        "  else:\n",
        "      return ['NA']"
      ],
      "metadata": {
        "id": "JUwhfztLz1iZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Preprocess repository information text"
      ],
      "metadata": {
        "id": "IdT4_DCwyK4Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text):\n",
        "    # Tokenize the text\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    # Remove punctuation and convert to lowercase\n",
        "    tokens = [word.lower() for word in tokens if word.isalpha()]\n",
        "\n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "\n",
        "    # Lemmatization\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
        "\n",
        "    return tokens"
      ],
      "metadata": {
        "id": "fqZtaf5t-ypP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dev_info = []\n",
        "for i in range(len(df['dev'])):\n",
        "  repo_concat = (' '.join(repos(df['dev'][i]))).split('.')\n",
        "  dev_info.append(repo_concat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-9_sJWK47js",
        "outputId": "5e78221f-4fdb-47fa-c15b-4ce2dbec700f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Repository Information Array:\n",
            "['This is a backend project. # Project Description:\\nThe project will have the following endpoints:\\n\\nPOST /register: Register a new user with a username and password.\\nPOST /login: Authenticate a user with a registered username and password.\\n\\n# Project Setup:\\n1. Create a new directory for your project and navigate to it in the terminal.\\n```\\nmkdir simple-auth-api\\ncd simple-auth-api\\n```\\n2. Initialize a new Node.js project.\\n```\\nnpm init -y\\n```\\n3. Install the necessary dependencies (Express and bcrypt for password hashing).\\n```\\nnpm install express bcrypt\\n4. Running the Project: Save the changes to index.js and Run the server\\n```\\nnode index.js\\n```\\n', 'None. # potterhead\\nExpress backend that creates a simple REST API for managing tasks. This project includes endpoints for retrieving a list of tasks, getting a specific task by ID, creating a new task, updating an existing task, and deleting a task. The tasks are stored in-memory for simplicity. The server runs on http://localhost:3000, and you can test the API using tools like Postman.\\n\\n\\n# Project Description:\\nThe project will have the following endpoints:\\n\\nGET /tasks: Retrieve a list of tasks.\\nGET /tasks/:id: Retrieve a specific task by ID.\\nPOST /tasks: Create a new task.\\nPUT /tasks/:id: Update an existing task by ID.\\nDELETE /tasks/:id: Delete a task by ID.\\n# Prerequisites:\\nMake sure you have Node.js and npm installed on your machine.\\n\\n# Project Setup:\\n1. Create a new directory for your project and navigate to it in the terminal.\\n```\\nmkdir simple-task-api\\ncd simple-task-api\\n```\\n2. Initialize a new Node.js project.\\n```\\nnpm init -y\\n```\\n3. Install the necessary dependencies (Express).\\n```\\nnpm install express\\n```\\n4. Running the project\\n  a. Save the changes to index.js.\\n  b. Run the server\\n```\\nnode index.js\\n```\\n\\n\\n']\n",
            "Repository Information Array:\n",
            "['The project repository contains the source code for a responsive webpage featuring a navigation bar and dynamic card grid, fetching and displaying information from an external API. # kkistheorz_repo\\nThis project involves the development of a responsive webpage with a user-friendly navigation bar and a dynamic card grid that displays information fetched from an external API. The webpage is designed to be accessible and visually appealing on various devices. The navigation bar provides easy access to different sections of the site, ensuring a seamless user experience. The dynamic card grid is populated with relevant data retrieved from the API, offering real-time information to the users. This project showcases front-end development skills, including responsive design principles and API integration, to create an interactive and engaging web application.\\n', 'Task Manager Web App. # repo_frontend\\nCreate a Task Manager Web App that allows users to efficiently manage their daily tasks. The application should have a user-friendly interface with features such as task creation, editing, deletion, and marking tasks as completed. Additionally, users should be able to categorize tasks, set due dates, and prioritize them. The Task Manager should provide a clean and intuitive design, making it easy for users to stay organized and focused on their responsibilities. Use HTML for the structure, CSS for styling, and JavaScript for dynamic functionality.\\n']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Implementing Dev2Vec"
      ],
      "metadata": {
        "id": "eUHjPQJgDaUr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Vectorizing the developers and the task"
      ],
      "metadata": {
        "id": "pv2rHKPx16VM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Doc2Vec.load(\"dev2vec_repos\")"
      ],
      "metadata": {
        "id": "q5PtMtFUBiQL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dev_embed = [[None] * len(inner_list) for inner_list in dev_info]"
      ],
      "metadata": {
        "id": "tB1RaoPSQdFf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(dev_info)):\n",
        "  dummy = np.empty_like(dev_info[i])\n",
        "  for j in range(len(dev_info[i])):\n",
        "    dummy = model.infer_vector(preprocess_text(dev_info[i][j]))\n",
        "    dev_embed[i][j] = dummy"
      ],
      "metadata": {
        "id": "U8BP3KQSDdG2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "task_embed = model.infer_vector(preprocess_text(task))"
      ],
      "metadata": {
        "id": "95QFIDEyEuD8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Install and import the required libraries"
      ],
      "metadata": {
        "id": "khxRbcqT2Dek"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-gpu\n",
        "!pip install tensorflow_hub\n",
        "!pip install hnswlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iSFuMR40G91r",
        "outputId": "04aa7696-8fb4-472f-df51-825c852b2daa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faiss-gpu\n",
            "  Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-gpu\n",
            "Successfully installed faiss-gpu-1.7.2\n",
            "Requirement already satisfied: tensorflow_hub in /usr/local/lib/python3.10/dist-packages (0.15.0)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_hub) (1.23.5)\n",
            "Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow_hub) (3.20.3)\n",
            "Collecting hnswlib\n",
            "  Downloading hnswlib-0.8.0.tar.gz (36 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from hnswlib) (1.23.5)\n",
            "Building wheels for collected packages: hnswlib\n",
            "  Building wheel for hnswlib (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hnswlib: filename=hnswlib-0.8.0-cp310-cp310-linux_x86_64.whl size=2287618 sha256=f46249999db8bc0679c03a8ea736781fab06db35963e8aa734fadb919d4271d2\n",
            "  Stored in directory: /root/.cache/pip/wheels/af/a9/3e/3e5d59ee41664eb31a4e6de67d1846f86d16d93c45f277c4e7\n",
            "Successfully built hnswlib\n",
            "Installing collected packages: hnswlib\n",
            "Successfully installed hnswlib-0.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_hub as hub\n",
        "import tensorflow as tf\n",
        "import hnswlib"
      ],
      "metadata": {
        "id": "d67Y6phMHLNa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Get k nearest neighbours using hnswlib"
      ],
      "metadata": {
        "id": "NuLy29dy2OLB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels = np.empty_like(dev_info)\n",
        "distances = np.empty_like(dev_info)\n",
        "for i in range(len(df['dev'])):\n",
        "  dev_tensor = tf.convert_to_tensor(dev_embed[i], dtype=tf.float32)\n",
        "  keyword_embeds = tf.convert_to_tensor(task_embed, dtype=tf.float32)\n",
        "  num_elements = len(dev_embed[i])\n",
        "  ids = np.arange(num_elements)\n",
        "  dim = dev_tensor.shape[1]\n",
        "  p = hnswlib.Index(space = 'l2', dim = dim)\n",
        "  p.init_index(max_elements = num_elements, ef_construction = 200, M = 16)\n",
        "  p.add_items(dev_embed[i], ids)\n",
        "  p.set_ef(50) # ef should always be > k\n",
        "  labels[i], distances[i] = p.knn_query(keyword_embeds, k = len(dev_embed[i]))"
      ],
      "metadata": {
        "id": "xr8nwoEwHgTQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81ef8fd3-cb78-4ef3-bb98-78bb12fbc3ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<__array_function__ internals>:180: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Resulting priority of developers"
      ],
      "metadata": {
        "id": "fGnz3gm22efF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "distance_avg = np.empty(len(df['dev']))\n",
        "for i in range(len(df['dev'])):\n",
        "  if(len(distances[i][0])<top_k):\n",
        "    distance_avg[i] = (np.sum(distances[i][0][:len(distances[i][0])]))/len(distances[i][0])\n",
        "  else:\n",
        "    distance_avg[i] = (np.sum(distances[i][0][:top_k]))/top_k"
      ],
      "metadata": {
        "id": "Guv1vvLXZjY4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sort_with_indices(arr):\n",
        "    indexed_arr = list(enumerate(arr))\n",
        "    sorted_arr = sorted(indexed_arr, key=lambda x: x[1])\n",
        "    sorted_indices = [index for index, _ in sorted_arr]\n",
        "    return sorted_indices\n",
        "\n",
        "priority_list = sort_with_indices(distance_avg)\n",
        "\n",
        "print('Priority Order is as follows:')\n",
        "if(num_recommend<=len(df['dev'])):\n",
        "  for i in range(num_recommend):\n",
        "    print(df['dev'][priority_list[i]])\n",
        "else:\n",
        "  print('Number asked for recommendation more than existing students')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WP17MIaLbz49",
        "outputId": "1066be4c-5d64-4c68-ac2f-561548fb0cd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Priority Order is as follows:\n",
            "kkistheorz\n",
            "ps-2810\n"
          ]
        }
      ]
    }
  ]
}